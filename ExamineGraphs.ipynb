{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!ls ../gcloud_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_experiments(experiment_ids, keys_to_filter, keys_to_keep, num_custom=0):\n",
    "    all_exp_res = {\n",
    "        \"Mix&MatchCH\": {},\n",
    "        \"Mix&MatchDP\": {},\n",
    "        \"Mix&Match+1.0Step\": {},\n",
    "        \"Genie\": {},\n",
    "        \"Uniform\": {},\n",
    "        \"IW-Uniform\": {},\n",
    "        \"IW-ERM\": {},\n",
    "        \"MMD\": {},\n",
    "        \"Mix&MatchCH+0.1Step\": {},\n",
    "        \"Mix&MatchDP+0.1Step\": {},\n",
    "        \"Validation\": {}\n",
    "    }\n",
    "    for i in range(num_custom):\n",
    "        all_exp_res['Only'+str(i)] = {}\n",
    "    for experiment_id in experiment_ids:\n",
    "        expers = glob.glob('../gcloud_data/{}/*'.format(experiment_id))\n",
    "        for exper in expers:\n",
    "            exper_name = os.path.basename(exper)\n",
    "            pickle_files = glob.glob(exper + '/*.p')\n",
    "            for file_id, pfile in enumerate(pickle_files):\n",
    "                if np.any([filterkey in pfile for filterkey in keys_to_filter]):\n",
    "                    continue\n",
    "                elif np.any([filterkey not in pfile for filterkey in keys_to_keep]):\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Loading file:\",pfile)\n",
    "                with open(pfile, 'rb') as f:\n",
    "                    manager = pickle.load(f)\n",
    "                    for idx, res in enumerate(manager.results):\n",
    "                        if \"coordinate-halving__True\" in pfile:\n",
    "                            label = \"Mix&MatchCH+0.1Step\"\n",
    "                        elif \"coordinate-halving\" in pfile:\n",
    "                            label = \"Mix&MatchCH\"\n",
    "                        elif \"delaunay-partitioning__True\" in pfile:\n",
    "                            label = \"Mix&MatchDP+0.1Step\"\n",
    "                        elif \"delaunay\" in pfile:\n",
    "                            label = \"Mix&MatchDP\"\n",
    "                        elif \"alpha-star\" in pfile:\n",
    "                            label = \"Genie\"\n",
    "                        elif \"validation\" in pfile:\n",
    "                            label = \"Validation\"\n",
    "                        elif \"tree-results\" in pfile:\n",
    "                            label = \"Mix&Match+1.0Step\"\n",
    "                        elif \"importance-weighted-uniform_constant\" in pfile:\n",
    "                            label = \"IW-Uniform\"\n",
    "                        elif \"uniform_constant\" in pfile:\n",
    "                            label = \"Uniform\"\n",
    "                        elif \"importance-weighted-erm_constant\" in pfile:\n",
    "                            label = \"IW-ERM\"\n",
    "                        elif \"mmd_constant\" in pfile:\n",
    "                            label = \"MMD\"\n",
    "                        elif \"custom\" in pfile:\n",
    "                            for i in range(num_custom):\n",
    "                                custom_id_list = ['0.0']*num_custom\n",
    "                                custom_id_list[i] = '1.0'\n",
    "                                custom_id = ','.join(custom_id_list)\n",
    "                                if \"custom_{}\".format(custom_id) in pfile:\n",
    "                                    label = \"Only\" + str(i)\n",
    "                                    break\n",
    "                        else:\n",
    "                            print(\"Skipping:\",pfile)\n",
    "                            continue\n",
    "                        validation_mf_fn_results_all = []\n",
    "                        for nodes in res.best_sols_all:\n",
    "                            validation_mf_fn_results = []\n",
    "                            for node in nodes:\n",
    "                                # Compute val\n",
    "                                validation_mf_fn_results.append(node.validation_mf_fn_results)\n",
    "                                \n",
    "                            validation_mf_fn_results_all.append(validation_mf_fn_results)\n",
    "                        all_exp_res[label][experiment_id] = {\n",
    "                            \"train_data\": manager.experiment_configurer.dataset_config.data.train,\n",
    "                            \"actual_costs_all\": res.actual_costs_all,\n",
    "                            \"test_mf_fn_results_all\": res.mf_fn_results_all,\n",
    "                            \"validation_mf_fn_results_all\": validation_mf_fn_results_all,\n",
    "                            \"recorders_all\": res.recorders_all[0],\n",
    "                        }\n",
    "    return all_exp_res\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_costs_and_vals(costs_all, mf_fn_results_all, alt_metric_to_include, label):\n",
    "    if label == \"Mix&Match+1.0Step\":\n",
    "        costs_all *= 2\n",
    "    avg_costs = np.average(costs_all, axis=1)\n",
    "    std_costs = np.std(costs_all, axis=1)\n",
    "    \n",
    "    num_classes = len(mf_fn_results_all[0,0].precision) if alt_metric_to_include else 0\n",
    "    if alt_metric_to_include == \"precision\":\n",
    "        f = lambda i: np.vectorize(lambda mf_fn_result: mf_fn_result.precision[i])\n",
    "    elif alt_metric_to_include == \"recall\":\n",
    "        f = lambda i: np.vectorize(lambda mf_fn_result: mf_fn_result.recall[i])\n",
    "    elif alt_metric_to_include == \"F\":\n",
    "        f = lambda i: np.vectorize(lambda mf_fn_result: mf_fn_result.f1[i])\n",
    "    elif alt_metric_to_include == \"support\":\n",
    "        f = lambda i: np.vectorize(lambda mf_fn_result: mf_fn_result.support[i])\n",
    "    elif alt_metric_to_include == \"auc_roc_ovo\":\n",
    "        f = np.vectorize(lambda mf_fn_result: mf_fn_result.auc_roc_ovo)\n",
    "    elif alt_metric_to_include == \"auc_roc_ovr\":\n",
    "        f = np.vectorize(lambda mf_fn_result: mf_fn_result.auc_roc_ovr)\n",
    "    else:\n",
    "        f = np.vectorize(lambda mf_fn_result: mf_fn_result.error)\n",
    "        \n",
    "    if alt_metric_to_include and \"auc_roc\" not in alt_metric_to_include:\n",
    "        vals_all = np.stack([f(i)(mf_fn_results_all) for i in range(num_classes)], axis=-1)\n",
    "    else:\n",
    "        vals_all = f(mf_fn_results_all)\n",
    "    avg_vals = np.average(vals_all, axis=1)\n",
    "    std_vals = np.std(vals_all, axis=1)\n",
    "    \n",
    "    return avg_costs, std_costs, avg_vals, std_vals\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_costs_and_vals_from_recorders(recorders_all, alt_metric_to_include, show_validation, label):\n",
    "    costs_all = None\n",
    "    mf_fn_results_all = None\n",
    "    for recorder in recorders_all:\n",
    "        costs_all = np.append(costs_all, np.array(recorder.results.costs)[:,None], axis=1) if costs_all is not None else np.array(recorder.results.costs)[:,None]\n",
    "        mf_fn_results = recorder.results.val_mf_fn_results if show_validation else recorder.results.test_mf_fn_results\n",
    "        mf_fn_results = [res[0] for res in mf_fn_results]\n",
    "        mf_fn_results_all = np.append(mf_fn_results_all, np.array(mf_fn_results)[:,None], axis=1) if mf_fn_results_all is not None else np.array(mf_fn_results)[:,None]\n",
    "        \n",
    "    return _get_costs_and_vals(costs_all=costs_all,\n",
    "                               mf_fn_results_all=mf_fn_results_all,\n",
    "                               alt_metric_to_include=alt_metric_to_include, \n",
    "                               label=label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_formats(num_custom):\n",
    "    fmt = {\n",
    "        \"Uniform\": {\n",
    "            \"fmt\": \"^-\",\n",
    "            \"color\": \"xkcd:black\"\n",
    "        },\n",
    "        \"IW-Uniform\": {\n",
    "            \"fmt\": \"|-\",\n",
    "            \"color\": \"xkcd:electric green\"\n",
    "        },\n",
    "        \"IW-ERM\": {\n",
    "            \"fmt\": \"_-\",\n",
    "            \"color\": \"xkcd:very light green\"\n",
    "        },\n",
    "        \"MMD\": {\n",
    "            \"fmt\": \"p-\",\n",
    "            \"color\": \"xkcd:powder pink\"\n",
    "        },\n",
    "        \"Mix&Match+1.0Step\": {\n",
    "            \"fmt\":\"o-\",\n",
    "            \"color\": \"xkcd:sky blue\"\n",
    "        },\n",
    "        \"Genie\": {\n",
    "            \"fmt\": \"s-\",\n",
    "            \"color\": \"xkcd:coral\"\n",
    "        },\n",
    "        \"Validation\": {\n",
    "            \"fmt\": \"P-\",\n",
    "            \"color\": \"xkcd:violet\"\n",
    "        },\n",
    "        \"Mix&MatchCH\": {\n",
    "            \"fmt\": \"x-\",\n",
    "            \"color\": \"xkcd:lavender\"\n",
    "        },\n",
    "        \"Mix&MatchCH+0.1Step\": {\n",
    "            \"fmt\":\"x-\",\n",
    "            \"color\": \"xkcd:olive\"\n",
    "        },\n",
    "        \"Mix&MatchDP\": {\n",
    "            \"fmt\": \"d-\",\n",
    "            \"color\": \"xkcd:plum\"\n",
    "        },\n",
    "        \"Mix&MatchDP+0.1Step\": {\n",
    "            \"fmt\":\"d-\",\n",
    "            \"color\": \"xkcd:sienna\"\n",
    "        }\n",
    "    }\n",
    "    for i in range(num_custom):\n",
    "        fmt['Only'+str(i)] = {\n",
    "            \"fmt\": \".-\",\n",
    "            \"color\": \"C{}\".format(i+1)\n",
    "        } \n",
    "    return fmt\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_experiments(all_exp_res, start_idx=0, num_custom=0, keys_to_exclude=[], stop_idx_tree=None, alt_metric_to_plot=None, target_class_idx=None, plot_validation=False, label_mapping={}, recorded_or_final_results='recorded'):\n",
    "    # fmts=['rs-','bo-','k^-','gx-','cd-','mh-']\n",
    "    fmt = get_formats(num_custom=num_custom)\n",
    "\n",
    "    print(\"Algorithm & SDG Iteration Budget & Average Error $\\pm$ $1$ std dev\")\n",
    "    for label, info in all_exp_res.items():\n",
    "        if info == {}: continue\n",
    "        if np.any([key in label for key in keys_to_exclude]): continue\n",
    "        # print(label)\n",
    "        costs_all = None\n",
    "        mf_fn_results_all = None\n",
    "        recorders_all = None\n",
    "        alt_metric_all = None\n",
    "        fmt_l = fmt[label]\n",
    "        for exp_id, data in info.items():\n",
    "            costs_all = np.hstack((costs_all, np.array(data['actual_costs_all']))) if costs_all is not None else np.array(data['actual_costs_all'])\n",
    "            recorders_all = np.hstack((recorders_all, np.array([data['recorders_all']]))) if recorders_all is not None else np.array(data['recorders_all'])\n",
    "            # print(costs_all.shape)\n",
    "            mf_fn_key = \"{}_mf_fn_results_all\".format(\"validation\" if plot_validation else \"test\")\n",
    "            mf_fn_results_all = np.concatenate((mf_fn_results_all, np.array(data[mf_fn_key])), axis=1) if mf_fn_results_all is not None else np.array(data[mf_fn_key])\n",
    "\n",
    "        # print(np.average(costs_all, axis=1))\n",
    "        if recorded_or_final_results == 'recorded':\n",
    "            avg_costs, std_costs, avg_vals, std_vals = _get_costs_and_vals_from_recorders(recorders_all, alt_metric_to_plot, plot_validation, label)\n",
    "        elif recorded_or_final_results == 'final':\n",
    "            avg_costs, std_costs, avg_vals, std_vals = _get_costs_and_vals(costs_all, mf_fn_results_all, alt_metric_to_plot, label)\n",
    "        else:\n",
    "            print('Recorded_or_final_results argument {} is invalid. Please set either recorded or final.')\n",
    "            assert False\n",
    "        if alt_metric_to_plot and \"auc\" not in alt_metric_to_plot:\n",
    "            avg_vals = avg_vals[:,target_class_idx]\n",
    "            std_vals = std_vals[:,target_class_idx]\n",
    "        \n",
    "        display_label = label if label not in label_mapping.keys() else label_mapping[label]\n",
    "        \n",
    "        if \"Mix&Match+1.0Step\" in label:\n",
    "            plt.errorbar(avg_costs[start_idx:stop_idx_tree], avg_vals[start_idx:stop_idx_tree], xerr=std_costs[start_idx:stop_idx_tree], yerr=std_vals[start_idx:stop_idx_tree], color=fmt_l['color'], fmt=fmt_l['fmt'], label=display_label)\n",
    "        else:\n",
    "            plt.errorbar(avg_costs[start_idx:], avg_vals[start_idx:], xerr=std_costs[start_idx:], yerr=std_vals[start_idx:], color=fmt_l['color'], fmt=fmt_l['fmt'], label=display_label)\n",
    "    plt.xlabel(\"SGD Iteration budget\")\n",
    "    plt_type = \"Validation\" if plot_validation else \"Test\" \n",
    "    if alt_metric_to_plot:\n",
    "        plt.ylabel(plt_type + \" \" + alt_metric_to_plot)\n",
    "    else:\n",
    "        plt.ylabel(plt_type + \" \" + \"error\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def print_table(all_exp_res, keys_to_exclude=[], num_classes=0, label_mapping={}, idx_to_display=0, include_cost=True, alt_metric_to_include=\"\", caption=\"CAPTION HERE\", table_label=\"DERP\", show_validation=False):\n",
    "    print(\"\\\\begin{table}[h!]\")\n",
    "    print(\"\\\\centering\")\n",
    "    print(\"\\\\begin{tabular}{ \"\\\n",
    "          + \"c|{}{}\".format(\"c|\" if include_cost else \"\",\n",
    "                                \"|\".join([\"c\" for i in range(num_classes)]) if alt_metric_to_include and \"auc_roc\" not in alt_metric_to_include else \"c\")\\\n",
    "          + \" }\")\n",
    "    print(\"\\\\hline\")\n",
    "    print(\"Algorithm & {}{} \\\\\\\\\".format(\n",
    "        \"Average Cost & \" if include_cost else \"\",\n",
    "        \"Average {}\".format(alt_metric_to_include.replace('_','\\_') if alt_metric_to_include else \"Error\")\n",
    "    ))\n",
    "    print(\"\\\\hline\")\n",
    "    for label, info in all_exp_res.items():\n",
    "        if info == {}: continue\n",
    "        if np.any([key in label for key in keys_to_exclude]): continue\n",
    "        costs_all = None\n",
    "        mf_fn_results_all = None\n",
    "        for exp_id, data in info.items():\n",
    "            # Get costs\n",
    "            costs_all = np.hstack((costs_all, np.array(data['actual_costs_all']))) if costs_all is not None else np.array(data['actual_costs_all'])\n",
    "            # Get error\n",
    "            mf_res_key = \"{}_mf_fn_results_all\".format(\"validation\" if show_validation else \"test\")\n",
    "            mf_fn_results_all = np.hstack((mf_fn_results_all, np.array(data[mf_res_key]))) if mf_fn_results_all is not None else np.array(data[mf_res_key])\n",
    "            \n",
    "        # Compute the costs\n",
    "        avg_costs, _, avg_vals, std_vals = _get_costs_and_vals(costs_all, mf_fn_results_all, alt_metric_to_include, label)\n",
    "        \n",
    "        display_label = label if label not in label_mapping.keys() else label_mapping[label]\n",
    "        \n",
    "        # Algo & Avg Err +/- std & Cl1 Pr +/- std, Re +/- std & Cl2 Pr +/- std, Re +/- std & ...\n",
    "        if alt_metric_to_include != \"\" and \"auc_roc\" not in alt_metric_to_include:\n",
    "            table_row_vals = \" & \".join([\"${:0.2f} \\pm {:0.2f}$\".format(avg_vals[idx_to_display, cl], std_vals[idx_to_display, cl]) for cl in range(num_classes)])\n",
    "        else:\n",
    "            table_row_vals = \"${:0.4f} \\pm {:0.4f}$\".format(avg_vals[idx_to_display], std_vals[idx_to_display])\n",
    "        print(\"{} & {} \\\\\\\\\".format(display_label.replace(\"&\",\"\\\\&\"),\n",
    "                                          # \"${:0.0f}$\".format(avg_costs[idx_to_display]) if include_cost else \"\",\n",
    "                                          table_row_vals))\n",
    "                                          \n",
    "    print(\"\\\\hline\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "    print(\"\\\\caption{\" + caption + \"}\")\n",
    "    print(\"\\\\label{tab:\" + table_label + \"}\")\n",
    "    print(\"\\\\end{table}\")\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!ls ../gcloud_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_custom = 4\n",
    "num_target_classes = 4\n",
    "label_mapping = {\n",
    "    \"Only0\": \"OnlyUS\",\n",
    "    \"Only1\": \"OnlyFrance\",\n",
    "    \"Only2\": \"OnlyItaly\",\n",
    "    \"Only3\": \"OnlySpain\",\n",
    "}\n",
    "# num_custom = 4\n",
    "# num_target_classes = 2\n",
    "# label_mapping = {\n",
    "#     \"Only0\": \"Only117878\",\n",
    "#     \"Only1\": \"Only117941\",\n",
    "#     \"Only2\": \"Only117945\",\n",
    "#     \"Only3\": \"Only117920\",\n",
    "# }\n",
    "# num_custom = 3\n",
    "# num_target_classes = 4\n",
    "# label_mapping = {\n",
    "#     \"Only0\": \"OnlyFrance\",\n",
    "#     \"Only1\": \"OnlyItaly\",\n",
    "#     \"Only2\": \"OnlySpain\",\n",
    "# }\n",
    "# num_custom = 3\n",
    "# num_target_classes = 4\n",
    "# label_mapping = {\n",
    "#     \"Only0\": \"OnlyFL\",\n",
    "#     \"Only1\": \"OnlyCT\",\n",
    "#     \"Only2\": \"OnlyOH\",\n",
    "# }\n",
    "# num_custom = 3\n",
    "# num_target_classes = 2\n",
    "# label_mapping = {\n",
    "#     \"Only0\": \"Only0.1\",\n",
    "#     \"Only1\": \"Only0.2\",\n",
    "#     \"Only2\": \"Only0.7\",\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_names = ['<>']\n",
    "record_alt_metrics = True\n",
    "# record_alt_metrics = False\n",
    "\n",
    "all_exp_res = get_experiments(experiment_names,['ACTUAL_MIXTURES','PRETRAINED_UNIFORM_BASELINE','INDIVIDUAL_SRC_BASELINE'],[\"\"], num_custom=num_custom)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "# num_custom=4\n",
    "keys_to_exclude=[]\n",
    "# num_target_classes = 4\n",
    "stop_idx_tree = 7\n",
    "plot_validation = True\n",
    "recorded_or_final_results='recorded'\n",
    "plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"auc_roc_ovo\", target_class_idx=0, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"auc_roc_ovr\", target_class_idx=0, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "for i in range(num_target_classes):\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"precision\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"recall\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"F\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"support\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "# num_custom=4\n",
    "keys_to_exclude=[]\n",
    "# num_target_classes = 4\n",
    "stop_idx_tree = 7\n",
    "plot_validation = False\n",
    "recorded_or_final_results='recorded'\n",
    "plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"auc_roc_ovo\", target_class_idx=0, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"auc_roc_ovr\", target_class_idx=0, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "for i in range(num_target_classes):\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"precision\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"recall\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"F\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n",
    "    plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=\"support\", target_class_idx=i, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "# num_custom=4\n",
    "keys_to_exclude=[]\n",
    "alt_metric_to_plot=\"\"\n",
    "target_class_idx = 0\n",
    "stop_idx_tree = 7\n",
    "plot_validation = False\n",
    "recorded_or_final_results='recorded'\n",
    "plot_experiments(all_exp_res, start_idx=start_idx, num_custom=num_custom, keys_to_exclude=keys_to_exclude, alt_metric_to_plot=alt_metric_to_plot, target_class_idx=target_class_idx, stop_idx_tree=stop_idx_tree, plot_validation=plot_validation, label_mapping=label_mapping, recorded_or_final_results=recorded_or_final_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_name = '<>'\n",
    "nbins = 20\n",
    "title=''\n",
    "training_data = all_exp_res['IW-Uniform'][experiment_name]['train_data']\n",
    "iw_column = training_data['importance_weights']\n",
    "iw_column.plot.hist(cumulative=True, bins=nbins,alpha=0.5)\n",
    "plt.title(title)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "caption=\"CAPTION\"\n",
    "lab=\"DERP\"\n",
    "include_cost=False\n",
    "alt_metric_to_include=\"\"\n",
    "# alt_metric_to_include=\"precision\"\n",
    "# alt_metric_to_include=\"recall\"\n",
    "# alt_metric_to_include=\"f1\"\n",
    "# alt_metric_to_include=\"support\"\n",
    "# alt_metric_to_include=\"auc_roc_ovo\"\n",
    "print_vals_at_idx = -1\n",
    "show_validation=False\n",
    "print_table(all_exp_res, keys_to_exclude=keys_to_exclude, num_classes=num_target_classes, label_mapping=label_mapping, idx_to_display=print_vals_at_idx, alt_metric_to_include=alt_metric_to_include, include_cost=include_cost, caption=caption, table_label=lab, show_validation=show_validation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}